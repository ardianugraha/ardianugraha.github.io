{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AKGuQdXil0e"
      },
      "source": [
        "# Deep Learning Lab @ 2023\n",
        "  ### Mohamed Ibn Khedher & Mounim A. El-Yacoubi\n",
        "  ### DATAIA 901\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yyHnv0Ril0g"
      },
      "source": [
        "# Introduction to Deep Learning\n",
        "Classification of Handwritten Digits by a Convolutional Neural Network (CNN)\n",
        "This study is carried out on MNIST, a dataset of handwritten numerals made up of 60000 images for training and 10000 for test. Each image has a size of 28x28 pixels, the gray level of each being between 0 and 255.\n",
        "\n",
        "Reference paper:\n",
        "\n",
        "@inproceedings{Lecun1998,\n",
        "    Author = {Y. Lecun and L. Bottou and Y. Bengio and P. Haffner},\n",
        "    title     = {Gradient-based learning applied to document recognition},\n",
        "    booktitle = {Proceedings of the IEEE},\n",
        "    year      = {1998},\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyGjnvlOil0h"
      },
      "source": [
        "# Demo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiELiSpYil0h"
      },
      "source": [
        "*This* Lab contains 6 parts. The goal is to compelete the TO DO parts.\n",
        "\n",
        "1. Data reading and splitting.\n",
        "2. Data visualisation.\n",
        "3. Define the model architecture\n",
        "4. Model fitting\n",
        "5. Model evaluation\n",
        "6. Implement new model architecture from a text description\n",
        "  * Implementation using defaut hyper parameters values\n",
        "  * Optimization on the validation dataset: modify the hyper parameters like **batch_size**, **epochs**, **validation_split**, etc.,to optimize performance on the validation dataset.\n",
        "  * After optimization, evaluate the final model on the test dataset.  \n",
        "\n",
        "\n",
        "\n",
        "7. Interpret your obtained reults."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrnRdT3vil0h"
      },
      "source": [
        "## Import the needed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4VZeHe53il0h"
      },
      "outputs": [],
      "source": [
        "#### First, you should import libraires.\n",
        "####\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from IPython.display import Image\n",
        "import sklearn\n",
        "import sklearn.model_selection\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "### for the color\n",
        "import termcolor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cW5LNU6Zil0i"
      },
      "source": [
        "# I) Data reading and splitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8z07M9Fil0i"
      },
      "source": [
        "This part consists of reading the MNIST dataset, split it into train, valid and test sets and display the number of images per set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eUKAd59Til0j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "2a73fa17-d54f-450a-f3a6-82adba0eed0e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-92518bcc681c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1) load data from MNIST Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.datasets.mnist' has no attribute 'TODO'"
          ]
        }
      ],
      "source": [
        "# I - Data reading & splitting\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# 1) load data from MNIST Dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.TODO\n",
        "\n",
        "x = np.concatenate((x_train, x_test))\n",
        "y = np.concatenate((y_train, y_test))\n",
        "\n",
        "train_size = 0.7\n",
        "x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(x, y, train_size=train_size, stratify=y, random_state=2023)\n",
        "\n",
        "\n",
        "train_size = 0.7\n",
        "x_train, x_valid, y_train, y_valid = sklearn.model_selection.train_test_split(x_train, y_train, train_size=train_size, stratify=y_train, random_state=2023)\n",
        "\n",
        "\n",
        "\n",
        "# Input image format\n",
        "rows, cols, channels = 28,28,1\n",
        "\n",
        "# 2) What does \"x_train\", \"y_train\", \"x_test\", \"y_test\", \"x_valid\" and \"y_valid\"  present ?\n",
        "# 3) Reshape \"x_train\", \"x_valid\" and \"x_test\" according to the input image format\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], TODO)\n",
        "x_test = x_test.reshape(x_test.shape[0],TODO)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0],TODO)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_valid = x_valid.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "x_valid /= 255\n",
        "\n",
        "#4) Display the number of images in train, valid and test sets\n",
        "\n",
        "print(x_train.TODO, 'train samples')\n",
        "print(x_valid.TODO, 'valid samples')\n",
        "print(x_test.TODO, 'test samples')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFANnkfJil0j"
      },
      "source": [
        "# II) Data visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgDgiH4pil0k"
      },
      "source": [
        "Which library is required to visualise the images ?  \n",
        "Complete the following commands to display the first 200 images from the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j4OV8TZAil0k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "79ace565-89b7-43ad-aa00-9ea2dcf3dd06"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-90aaded07814>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#1) Which library is required to  display images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mTODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#2) Complete the script to display the first 200 images from the MNIST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'TODO'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# II - Data visualisation\n",
        "\n",
        "#1) Which library is required to  display images\n",
        "import TODO\n",
        "\n",
        "#2) Complete the script to display the first 200 images from the MNIST dataset\n",
        "\n",
        "plt.figure(figsize=(7.195, 3.841), dpi=100)\n",
        "\n",
        "for i in range(200):\n",
        "    plt.subplot(10,20,i+1)\n",
        "    plt.imshow(x_train[i].TODO, cmap='gray')\n",
        "    plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4QXORcGil0k"
      },
      "source": [
        "# III) Model architetcure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MW4oIOlail0k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "8ddaa24b-c585-46d6-cd0a-59d992b7fa92"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-43d0b41f2e14>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#2) Verify your proposition using a predefined command to show the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTODO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'TODO'"
          ]
        }
      ],
      "source": [
        "#III - Model Architecture\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "#1) Describe each model layer, specify the input/output dimensions\n",
        "#2) Verify your proposition using a predefined command to show the model architecture\n",
        "\n",
        "model.TODO()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jWD4Nvjil0k"
      },
      "source": [
        "# IV) Fitting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. First *Fitting/Evaluation* using a selected values of hyper parameters\n",
        "* ####  Fitting on the training dataset\n",
        "* #### Validation on the validation dataset\n",
        "* #### Evaluation on the test dataset"
      ],
      "metadata": {
        "id": "brJd6EyE2oTo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MwxVCfWail0k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "1d08741f-83ee-443e-b6a3-b4a134a46d89"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c41ea2d3d612>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTODO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTODO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTODO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.utils' has no attribute 'TODO'"
          ]
        }
      ],
      "source": [
        "# IV - Fitting\n",
        "\n",
        "# 1) convert labels to categorical type\n",
        "\n",
        "num_classes=10\n",
        "y_train = keras.utils.TODO(y_train, num_classes)\n",
        "y_test = keras.utils.TODO(y_test, num_classes)\n",
        "y_valid = keras.utils.TODO(y_valid, num_classes)\n",
        "\n",
        "# 2) complete the following command to fit the Deep neural model.\n",
        "# 3) select the hyperparameters values according to your choice\n",
        "\n",
        "model.TODO(x_train, y_train,\n",
        "          batch_size=TODO,\n",
        "          epochs=TODO,\n",
        "          verbose=1,\n",
        "          validation_data=(x_valid,y_valid))\n",
        "\n",
        "# 4) What does each hyperparameter presents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKU-dJn7il0l"
      },
      "source": [
        "# Model evaluation on the test dataset\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7KRfBVOTil0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "5457d016-6e30-4008-e7d1-79aa6f6d3cc1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-29bbbf96400e>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1) complete the command to evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTODO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 2) complete the command to display model performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'TODO'"
          ]
        }
      ],
      "source": [
        "# V - Evaluate the model\n",
        "\n",
        "# 1) complete the command to evaluate the model\n",
        "\n",
        "score = model.TODO(x_test, y_test, verbose=0)\n",
        "\n",
        "# 2) complete the command to display model performance\n",
        "\n",
        "print('Test loss:', TODO)\n",
        "print('Test accuracy:', TODO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fayg3s07il0l"
      },
      "source": [
        "**NB:** Modify hyper parameters like **batch_size**, **epochs**,\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "**validation_split**, etc., used so as to improve the results. Make\n",
        "an analysis and interpretation in light of the new results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQnWrwF6il0l"
      },
      "source": [
        "#### To analyze results, plot the confusion matrix using the following command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pO4ZxyyEil0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "af1f0842-0c9c-45a1-cd66-008651fecc73"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e0e3a74c76a0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#### To analyze results, plot the confusion matrix using the following command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#Predict the test results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_test_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my_predict_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#### To analyze results, plot the confusion matrix using the following command\n",
        "#Predict the test results\n",
        "y_predict = model.predict(x_test)\n",
        "y_test_labels = y_test.argmax(1)\n",
        "y_predict_labels = y_predict.argmax(1)\n",
        "#confusion matrix and classification report\n",
        "print(\"Confusion Matrix\\n\",confusion_matrix(y_test_labels,y_predict_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmtbv18bil0l"
      },
      "source": [
        "# VI) New Model Architetcure & Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzV_0Y_0il0m"
      },
      "source": [
        "Now, It is time to create a new model and evaluate its performance on the MNIST dataset. We suggest to implement the following architecure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJtuwUhtil0m"
      },
      "source": [
        "## Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Convolutional layer with 30 feature maps of size 5×5.\n",
        "* Pooling layer taking the max over 2*2 patches.\n",
        "* Convolutional layer with 15 feature maps of size 3×3.\n",
        "* Pooling layer taking the max over 2*2 patches.\n",
        "* Dropout layer with a probability of 20%.\n",
        "* Flatten layer.\n",
        "* Fully connected layer with 128 neurons and rectifier activation.\n",
        "* Fully connected layer with 50 neurons and rectifier activation.\n",
        "* Output layer."
      ],
      "metadata": {
        "id": "ZU3xT4NMPAYO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xMB7ntAIil0m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "93f25291-b3c9-43d5-c044-5bbb7b124c81"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-2686c58eb119>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    TO DO\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# VI - Create a new model and evaluate its performance\n",
        "def New_model():\n",
        "    # 1) create model\n",
        "    TO DO\n",
        "    # Compile model\n",
        "    model.compile(loss='categorical_crossentropy', keras.optimizers.Adadelta(), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# 2) Model evaluation\n",
        "# build the model\n",
        "model = New_model()\n",
        "\n",
        "# Fit the model\n",
        "#############################################################\n",
        "\n",
        "\n",
        "######## Insert your code here                 ##############\n",
        "\n",
        "\n",
        "#############################################################\n",
        "\n",
        "\n",
        "# Optimize the hyper parameters values to obtain the most efficient model on the validation dataset\n",
        "# In your final report, describe your proposed strategy of model optimization\n",
        "\n",
        "# Implement our strategy here\n",
        "\n",
        "#############################################################\n",
        "\n",
        "\n",
        "######## Insert your code here                 ##############\n",
        "\n",
        "\n",
        "#############################################################\n",
        "\n",
        "## Final evaluation of the model on the test dataset\n",
        "\n",
        "#############################################################\n",
        "\n",
        "\n",
        "######## Insert your code here                 ##############\n",
        "\n",
        "\n",
        "#############################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH4C34ZYil0m"
      },
      "outputs": [],
      "source": [
        "#### To analyze results, plot the confusion matrix using the following command\n",
        "\n",
        "#############################################################\n",
        "\n",
        "\n",
        "######## Insert your code here                 ##############\n",
        "\n",
        "\n",
        "#############################################################\n",
        "\n",
        "\n",
        "\n",
        "#############################################################\n",
        "\n",
        "\n",
        "######## Interpret the obtained results        ##############\n",
        "\n",
        "\n",
        "#############################################################"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}